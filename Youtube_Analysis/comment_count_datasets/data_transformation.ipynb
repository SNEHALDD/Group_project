{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/zara/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#import dependecies\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import scipy\n",
    "from textblob import TextBlob\n",
    "from sklearn import metrics\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z12rwfnyyrbsefonb232i5ehdxzkjzjs2</td>\n",
       "      <td>Lisa Wellas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+447935454150 lovely girl talk to me xxx﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>z130wpnwwnyuetxcn23xf5k5ynmkdpjrj04</td>\n",
       "      <td>jason graham</td>\n",
       "      <td>2015-05-29T02:26:10.652000</td>\n",
       "      <td>I always end up coming back to this song&lt;br /&gt;﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>z13vsfqirtavjvu0t22ezrgzyorwxhpf3</td>\n",
       "      <td>Ajkal Khan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my sister just received over 6,500 new &lt;a rel=...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z12wjzc4eprnvja4304cgbbizuved35wxcs</td>\n",
       "      <td>Dakota Taylor</td>\n",
       "      <td>2015-05-29T02:13:07.810000</td>\n",
       "      <td>Cool﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z13xjfr42z3uxdz2223gx5rrzs3dt5hna</td>\n",
       "      <td>Jihad Naser</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hello I&amp;#39;am from Palastine﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>LneaDw26bFu3RCmyrWyP9S6wh1h9dBv3X95g1HzKAb4</td>\n",
       "      <td>Dany PK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUBSCRIBE TO MY CHANNEL X PLEASE!. SPARE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>LneaDw26bFsD65dtIvAEObWYIYnFTqQDKBek_Ypz3J8</td>\n",
       "      <td>SmexyFriedChicken</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Check out my videos guy! :) Hope you guys had ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>LneaDw26bFuvs-8oWkLpAFa6g3QHpWD8k7sbbMP3Bg8</td>\n",
       "      <td>The Guy That's Done Everything</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3 yrs ago I had a health scare but thankfully ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>z12hfp2wmyuqztkw504cgblyxtbsxjuzeow0k</td>\n",
       "      <td>Jesse Pinkman</td>\n",
       "      <td>2015-05-06T11:42:44.601000</td>\n",
       "      <td>Rihanna looks so beautiful with red hair ;)﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>z13tsbc5vvn0hdozz04chjt51lq1cvris0k</td>\n",
       "      <td>Gaming Gaming</td>\n",
       "      <td>2015-05-06T10:56:35.972000</td>\n",
       "      <td>857.482.940 views AWESOME !!!!!!!!!!!!!!!!!!!!...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>448 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      COMMENT_ID  \\\n",
       "0              z12rwfnyyrbsefonb232i5ehdxzkjzjs2   \n",
       "1            z130wpnwwnyuetxcn23xf5k5ynmkdpjrj04   \n",
       "2              z13vsfqirtavjvu0t22ezrgzyorwxhpf3   \n",
       "3            z12wjzc4eprnvja4304cgbbizuved35wxcs   \n",
       "4              z13xjfr42z3uxdz2223gx5rrzs3dt5hna   \n",
       "..                                           ...   \n",
       "443  LneaDw26bFu3RCmyrWyP9S6wh1h9dBv3X95g1HzKAb4   \n",
       "444  LneaDw26bFsD65dtIvAEObWYIYnFTqQDKBek_Ypz3J8   \n",
       "445  LneaDw26bFuvs-8oWkLpAFa6g3QHpWD8k7sbbMP3Bg8   \n",
       "446        z12hfp2wmyuqztkw504cgblyxtbsxjuzeow0k   \n",
       "447          z13tsbc5vvn0hdozz04chjt51lq1cvris0k   \n",
       "\n",
       "                             AUTHOR                        DATE  \\\n",
       "0                       Lisa Wellas                         NaN   \n",
       "1                      jason graham  2015-05-29T02:26:10.652000   \n",
       "2                        Ajkal Khan                         NaN   \n",
       "3                     Dakota Taylor  2015-05-29T02:13:07.810000   \n",
       "4                       Jihad Naser                         NaN   \n",
       "..                              ...                         ...   \n",
       "443                         Dany PK                         NaN   \n",
       "444               SmexyFriedChicken                         NaN   \n",
       "445  The Guy That's Done Everything                         NaN   \n",
       "446                   Jesse Pinkman  2015-05-06T11:42:44.601000   \n",
       "447                   Gaming Gaming  2015-05-06T10:56:35.972000   \n",
       "\n",
       "                                               CONTENT  CLASS  \n",
       "0            +447935454150 lovely girl talk to me xxx﻿      1  \n",
       "1      I always end up coming back to this song<br />﻿      0  \n",
       "2    my sister just received over 6,500 new <a rel=...      1  \n",
       "3                                                Cool﻿      0  \n",
       "4                       Hello I&#39;am from Palastine﻿      1  \n",
       "..                                                 ...    ...  \n",
       "443           SUBSCRIBE TO MY CHANNEL X PLEASE!. SPARE      1  \n",
       "444  Check out my videos guy! :) Hope you guys had ...      1  \n",
       "445  3 yrs ago I had a health scare but thankfully ...      1  \n",
       "446       Rihanna looks so beautiful with red hair ;)﻿      0  \n",
       "447  857.482.940 views AWESOME !!!!!!!!!!!!!!!!!!!!...      0  \n",
       "\n",
       "[448 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import files\n",
    "df1=pd.read_csv(\"../Youtube-Spam-Collection-v1/Youtube01-Psy.csv\")\n",
    "df2=pd.read_csv(\"../Youtube-Spam-Collection-v1/Youtube02-KatyPerry.csv\")\n",
    "df3=pd.read_csv(\"../Youtube-Spam-Collection-v1/Youtube03-LMFAO.csv\")\n",
    "df4=pd.read_csv(\"../Youtube-Spam-Collection-v1/Youtube04-Eminem.csv\")\n",
    "df5=pd.read_csv(\"../Youtube-Spam-Collection-v1/Youtube05-Shakira.csv\")\n",
    "\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>COMMENT_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z13uwn2heqndtr5g304ccv5j5kqqzxjadmc0k</td>\n",
       "      <td>Corey Wilson</td>\n",
       "      <td>2015-05-28T21:39:52.376000</td>\n",
       "      <td>&lt;a href=\"http://www.youtube.com/watch?v=KQ6zr6...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>z124jvczaz3dxhnbc04cffk43oiugj25yzo0k</td>\n",
       "      <td>Epic Gaming</td>\n",
       "      <td>2015-05-28T20:07:20.610000</td>\n",
       "      <td>wierd but funny﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>z13tczjy5xj0vjmu5231unho1ofey5zdk</td>\n",
       "      <td>LaS Music</td>\n",
       "      <td>2015-05-28T19:23:35.355000</td>\n",
       "      <td>Hey guys, I&amp;#39;m a human.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;Bu...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z13tzr0hdpnayhqqc04cd3zqqqjkf3ngckk0k</td>\n",
       "      <td>Cheryl Fox</td>\n",
       "      <td>2015-05-28T17:49:35.294000</td>\n",
       "      <td>Party Rock....lol...who wants to shuffle!!!﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z12pcvix4zedcjvyb04ccr1r0mr2g5xwyng0k</td>\n",
       "      <td>PATRICK_TW</td>\n",
       "      <td>2015-05-28T16:28:26.818000</td>\n",
       "      <td>Party rock﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>z13lvr4iupatjlrem231yvpxolzvspwdl</td>\n",
       "      <td>Salty Croc</td>\n",
       "      <td>2014-07-22T04:20:37.489000</td>\n",
       "      <td>Like this comment for no reason﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>z12lxhrqdkyusbkji04cihtrvn3jvxnqszg0k</td>\n",
       "      <td>Bob Orton</td>\n",
       "      <td>2014-07-22T00:26:50.820000</td>\n",
       "      <td>love this song﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>z12xhdjrsxm3v550w22oynsjrnmvjhkvj</td>\n",
       "      <td>LuckyMusiqLive</td>\n",
       "      <td>2014-07-21T22:25:54.048000</td>\n",
       "      <td>this song is awesome. these guys are the best....</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>z13msngo3qvwx1ym223pehqgouexzdmnm</td>\n",
       "      <td>xXxPWND 420xXx</td>\n",
       "      <td>2014-07-21T11:05:51.945000</td>\n",
       "      <td>HOW MANY THUMBS UP FOR LOUIS SAVING THE DAY!?!?﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>z120hptrylzqzdsoj04cepaonmuyyr1afj0</td>\n",
       "      <td>Matheus Macedo</td>\n",
       "      <td>2014-07-21T04:24:24.585000</td>\n",
       "      <td>NICE :3﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>438 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                COMMENT_ID          AUTHOR  \\\n",
       "0    z13uwn2heqndtr5g304ccv5j5kqqzxjadmc0k    Corey Wilson   \n",
       "1    z124jvczaz3dxhnbc04cffk43oiugj25yzo0k     Epic Gaming   \n",
       "2        z13tczjy5xj0vjmu5231unho1ofey5zdk       LaS Music   \n",
       "3    z13tzr0hdpnayhqqc04cd3zqqqjkf3ngckk0k      Cheryl Fox   \n",
       "4    z12pcvix4zedcjvyb04ccr1r0mr2g5xwyng0k      PATRICK_TW   \n",
       "..                                     ...             ...   \n",
       "433      z13lvr4iupatjlrem231yvpxolzvspwdl      Salty Croc   \n",
       "434  z12lxhrqdkyusbkji04cihtrvn3jvxnqszg0k       Bob Orton   \n",
       "435      z12xhdjrsxm3v550w22oynsjrnmvjhkvj  LuckyMusiqLive   \n",
       "436      z13msngo3qvwx1ym223pehqgouexzdmnm  xXxPWND 420xXx   \n",
       "437    z120hptrylzqzdsoj04cepaonmuyyr1afj0  Matheus Macedo   \n",
       "\n",
       "                           DATE  \\\n",
       "0    2015-05-28T21:39:52.376000   \n",
       "1    2015-05-28T20:07:20.610000   \n",
       "2    2015-05-28T19:23:35.355000   \n",
       "3    2015-05-28T17:49:35.294000   \n",
       "4    2015-05-28T16:28:26.818000   \n",
       "..                          ...   \n",
       "433  2014-07-22T04:20:37.489000   \n",
       "434  2014-07-22T00:26:50.820000   \n",
       "435  2014-07-21T22:25:54.048000   \n",
       "436  2014-07-21T11:05:51.945000   \n",
       "437  2014-07-21T04:24:24.585000   \n",
       "\n",
       "                                               CONTENT  CLASS  COMMENT_COUNT  \n",
       "0    <a href=\"http://www.youtube.com/watch?v=KQ6zr6...      0              1  \n",
       "1                                     wierd but funny﻿      0              1  \n",
       "2    Hey guys, I&#39;m a human.<br /><br /><br />Bu...      1              1  \n",
       "3         Party Rock....lol...who wants to shuffle!!!﻿      0              1  \n",
       "4                                          Party rock﻿      0              1  \n",
       "..                                                 ...    ...            ...  \n",
       "433                   Like this comment for no reason﻿      1              1  \n",
       "434                                    love this song﻿      0              1  \n",
       "435  this song is awesome. these guys are the best....      1              1  \n",
       "436   HOW MANY THUMBS UP FOR LOUIS SAVING THE DAY!?!?﻿      1              1  \n",
       "437                                           NICE :3﻿      0              1  \n",
       "\n",
       "[438 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add amount of times each user made a comment on the video column\n",
    "df1[\"COMMENT_COUNT\"]=df1.groupby(['AUTHOR'])['CONTENT'].transform('count')\n",
    "df2[\"COMMENT_COUNT\"]=df2.groupby(['AUTHOR'])['CONTENT'].transform('count')\n",
    "df3[\"COMMENT_COUNT\"]=df3.groupby(['AUTHOR'])['CONTENT'].transform('count')\n",
    "df4[\"COMMENT_COUNT\"]=df4.groupby(['AUTHOR'])['CONTENT'].transform('count')\n",
    "df5[\"COMMENT_COUNT\"]=df5.groupby(['AUTHOR'])['CONTENT'].transform('count')\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COMMENT_ID       object\n",
       "AUTHOR           object\n",
       "DATE             object\n",
       "CONTENT          object\n",
       "CLASS             int64\n",
       "COMMENT_COUNT     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zara/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "/Users/zara/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>COMMENT_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>huh anyway check tube channel kobyoshi</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hey guys check new channel first vid us monkey...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test say murdev com</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shaking sexy ass channel enjoy _</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watch v vtarggvgtwq check</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>billion views planet lol</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>watching</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>subscribe call duty vids give aways goal subs</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>hi guys please android photo editor download t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>first billion viewed thought really cool billi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               CONTENT CLASS COMMENT_COUNT\n",
       "0               huh anyway check tube channel kobyoshi     1             1\n",
       "1    hey guys check new channel first vid us monkey...     1             1\n",
       "2                                  test say murdev com     1             1\n",
       "3                     shaking sexy ass channel enjoy _     1             1\n",
       "4                            watch v vtarggvgtwq check     1             1\n",
       "..                                                 ...   ...           ...\n",
       "345                           billion views planet lol     0             1\n",
       "346                                           watching     0             1\n",
       "347      subscribe call duty vids give aways goal subs     1             1\n",
       "348  hi guys please android photo editor download t...     1             1\n",
       "349  first billion viewed thought really cool billi...     0             1\n",
       "\n",
       "[350 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean data- df1\n",
    "df1=df1.drop(columns=[\"COMMENT_ID\", \"AUTHOR\",\"DATE\"])\n",
    "df1=df1.dropna()\n",
    "#remove urls, special characters, and punctuations, trailing spaces, emojis\n",
    "df1=df1.astype(str).apply(lambda x: x.str.encode('ascii','ignore').str.decode('ascii'))\n",
    "df1['CONTENT']= df1['CONTENT'].str.replace('http[s]?://(?:[a-zA-Z]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',' ')\n",
    "df1['CONTENT']=df1['CONTENT'].str.replace('\\W',' ',regex=True)\n",
    "df1['CONTENT']=df1['CONTENT'].str.replace('\\d+',' ')\n",
    "#everything to lowercase\n",
    "df1['CONTENT']=df1['CONTENT'].str.lower()\n",
    "#remove stopwords\n",
    "stop_words=set(stopwords.words('english'))\n",
    "def remove_stop(x):\n",
    "    return (\" \").join([word for word in str(x).split() if word not in stop_words])\n",
    "\n",
    "df1[\"CONTENT\"]=df1[\"CONTENT\"].apply(lambda x: remove_stop(x))\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zara/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "/Users/zara/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>COMMENT_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love much also generate free leads auto pilot amp</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vote sones please vips please help us gt lt</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey guys please join fight help abused mistrea...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>song</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hey everyone watch trailer</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>song means much thank sooooooooooooooooooooooo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>lt</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>katy perry dcio cabelo decio hair years age fa...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>honestly speaking except taylor swift adele li...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>going reach billion first katy taylor</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               CONTENT CLASS COMMENT_COUNT\n",
       "0    love much also generate free leads auto pilot amp     1             1\n",
       "1          vote sones please vips please help us gt lt     1             1\n",
       "2    hey guys please join fight help abused mistrea...     1             1\n",
       "3                                                 song     1             1\n",
       "4                           hey everyone watch trailer     1             1\n",
       "..                                                 ...   ...           ...\n",
       "345  song means much thank sooooooooooooooooooooooo...     0             1\n",
       "346                                                 lt     0             1\n",
       "347  katy perry dcio cabelo decio hair years age fa...     1             1\n",
       "348  honestly speaking except taylor swift adele li...     0             1\n",
       "349              going reach billion first katy taylor     0             1\n",
       "\n",
       "[350 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean data- df2\n",
    "df2=df2.drop(columns=[\"COMMENT_ID\", \"AUTHOR\",\"DATE\"])\n",
    "df2=df2.dropna()\n",
    "#remove urls, special characters, and punctuations, trailing spaces, emojis\n",
    "df2=df2.astype(str).apply(lambda x: x.str.encode('ascii','ignore').str.decode('ascii'))\n",
    "df2['CONTENT']= df2['CONTENT'].str.replace('http[s]?://(?:[a-zA-Z]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',' ')\n",
    "df2['CONTENT']=df2['CONTENT'].str.replace('\\W',' ',regex=True)\n",
    "df2['CONTENT']=df2['CONTENT'].str.replace('\\d+',' ')\n",
    "#everything to lowercase\n",
    "df2['CONTENT']=df2['CONTENT'].str.lower()\n",
    "#remove stopwords\n",
    "stop_words=set(stopwords.words('english'))\n",
    "def remove_stop(x):\n",
    "    return (\" \").join([word for word in str(x).split() if word not in stop_words])\n",
    "\n",
    "df2[\"CONTENT\"]=df2[\"CONTENT\"].apply(lambda x: remove_stop(x))\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zara/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "/Users/zara/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>COMMENT_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>href best part</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wierd funny</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey guys human br br br want human want sexy f...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>party rock lol wants shuffle</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>party rock</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>like comment reason</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>love song</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>song awesome guys best love video hilarious lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>many thumbs louis saving day</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>nice</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>438 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               CONTENT CLASS COMMENT_COUNT\n",
       "0                                       href best part     0             1\n",
       "1                                          wierd funny     0             1\n",
       "2    hey guys human br br br want human want sexy f...     1             1\n",
       "3                         party rock lol wants shuffle     0             1\n",
       "4                                           party rock     0             1\n",
       "..                                                 ...   ...           ...\n",
       "433                                like comment reason     1             1\n",
       "434                                          love song     0             1\n",
       "435  song awesome guys best love video hilarious lo...     1             1\n",
       "436                       many thumbs louis saving day     1             1\n",
       "437                                               nice     0             1\n",
       "\n",
       "[438 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean data- df3\n",
    "df3=df3.drop(columns=[\"COMMENT_ID\", \"AUTHOR\",\"DATE\"])\n",
    "df3=df3.dropna()\n",
    "#remove urls, special characters, and punctuations, trailing spaces, emojis\n",
    "df3=df3.astype(str).apply(lambda x: x.str.encode('ascii','ignore').str.decode('ascii'))\n",
    "df3['CONTENT']= df3['CONTENT'].str.replace('http[s]?://(?:[a-zA-Z]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',' ')\n",
    "df3['CONTENT']=df3['CONTENT'].str.replace('\\W',' ',regex=True)\n",
    "df3['CONTENT']=df3['CONTENT'].str.replace('\\d+',' ')\n",
    "#everything to lowercase\n",
    "df3['CONTENT']=df3['CONTENT'].str.lower()\n",
    "#remove stopwords\n",
    "stop_words=set(stopwords.words('english'))\n",
    "def remove_stop(x):\n",
    "    return (\" \").join([word for word in str(x).split() if word not in stop_words])\n",
    "\n",
    "df3[\"CONTENT\"]=df3[\"CONTENT\"].apply(lambda x: remove_stop(x))\n",
    "\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zara/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "/Users/zara/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>COMMENT_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>huh anyway check tube channel kobyoshi</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hey guys check new channel first vid us monkey...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test say murdev com</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shaking sexy ass channel enjoy _</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watch v vtarggvgtwq check</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>billion views planet lol</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>watching</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>subscribe call duty vids give aways goal subs</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>hi guys please android photo editor download t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>first billion viewed thought really cool billi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               CONTENT CLASS COMMENT_COUNT\n",
       "0               huh anyway check tube channel kobyoshi     1             1\n",
       "1    hey guys check new channel first vid us monkey...     1             1\n",
       "2                                  test say murdev com     1             1\n",
       "3                     shaking sexy ass channel enjoy _     1             1\n",
       "4                            watch v vtarggvgtwq check     1             1\n",
       "..                                                 ...   ...           ...\n",
       "345                           billion views planet lol     0             1\n",
       "346                                           watching     0             1\n",
       "347      subscribe call duty vids give aways goal subs     1             1\n",
       "348  hi guys please android photo editor download t...     1             1\n",
       "349  first billion viewed thought really cool billi...     0             1\n",
       "\n",
       "[350 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean data- df4\n",
    "df4=df4.drop(columns=[\"COMMENT_ID\", \"AUTHOR\",\"DATE\"])\n",
    "df4=df4.dropna()\n",
    "#remove urls, special characters, and punctuations, trailing spaces, emojis\n",
    "df4=df1.astype(str).apply(lambda x: x.str.encode('ascii','ignore').str.decode('ascii'))\n",
    "df4['CONTENT']= df4['CONTENT'].str.replace('http[s]?://(?:[a-zA-Z]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',' ')\n",
    "df4['CONTENT']=df4['CONTENT'].str.replace('\\W',' ',regex=True)\n",
    "df4['CONTENT']=df4['CONTENT'].str.replace('\\d+',' ')\n",
    "#everything to lowercase\n",
    "df4['CONTENT']=df4['CONTENT'].str.lower()\n",
    "#remove stopwords\n",
    "stop_words=set(stopwords.words('english'))\n",
    "def remove_stop(x):\n",
    "    return (\" \").join([word for word in str(x).split() if word not in stop_words])\n",
    "\n",
    "df4[\"CONTENT\"]=df4[\"CONTENT\"].apply(lambda x: remove_stop(x))\n",
    "\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zara/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "/Users/zara/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>COMMENT_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>huh anyway check tube channel kobyoshi</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hey guys check new channel first vid us monkey...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test say murdev com</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shaking sexy ass channel enjoy _</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watch v vtarggvgtwq check</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>billion views planet lol</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>watching</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>subscribe call duty vids give aways goal subs</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>hi guys please android photo editor download t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>first billion viewed thought really cool billi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               CONTENT CLASS COMMENT_COUNT\n",
       "0               huh anyway check tube channel kobyoshi     1             1\n",
       "1    hey guys check new channel first vid us monkey...     1             1\n",
       "2                                  test say murdev com     1             1\n",
       "3                     shaking sexy ass channel enjoy _     1             1\n",
       "4                            watch v vtarggvgtwq check     1             1\n",
       "..                                                 ...   ...           ...\n",
       "345                           billion views planet lol     0             1\n",
       "346                                           watching     0             1\n",
       "347      subscribe call duty vids give aways goal subs     1             1\n",
       "348  hi guys please android photo editor download t...     1             1\n",
       "349  first billion viewed thought really cool billi...     0             1\n",
       "\n",
       "[350 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean data- df5\n",
    "df5=df5.drop(columns=[\"COMMENT_ID\", \"AUTHOR\",\"DATE\"])\n",
    "df5=df5.dropna()\n",
    "#remove urls, special characters, and punctuations, trailing spaces, emojis\n",
    "df5=df1.astype(str).apply(lambda x: x.str.encode('ascii','ignore').str.decode('ascii'))\n",
    "df5['CONTENT']= df5['CONTENT'].str.replace('http[s]?://(?:[a-zA-Z]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',' ')\n",
    "df5['CONTENT']=df5['CONTENT'].str.replace('\\W',' ',regex=True)\n",
    "df5['CONTENT']=df5['CONTENT'].str.replace('\\d+',' ')\n",
    "#everything to lowercase\n",
    "df5['CONTENT']=df5['CONTENT'].str.lower()\n",
    "#remove stopwords\n",
    "stop_words=set(stopwords.words('english'))\n",
    "def remove_stop(x):\n",
    "    return (\" \").join([word for word in str(x).split() if word not in stop_words])\n",
    "\n",
    "df5[\"CONTENT\"]=df5[\"CONTENT\"].apply(lambda x: remove_stop(x))\n",
    "\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>COMMENT_COUNT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>href best part</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wierd funny</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey guys human br br br want human want sexy f...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>party rock lol wants shuffle</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>party rock</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>like comment reason</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>love song</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>song awesome guys best love video hilarious lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>many thumbs louis saving day</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>nice</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>438 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               CONTENT COMMENT_COUNT CLASS\n",
       "0                                       href best part             1     0\n",
       "1                                          wierd funny             1     0\n",
       "2    hey guys human br br br want human want sexy f...             1     1\n",
       "3                         party rock lol wants shuffle             1     0\n",
       "4                                           party rock             1     0\n",
       "..                                                 ...           ...   ...\n",
       "433                                like comment reason             1     1\n",
       "434                                          love song             1     0\n",
       "435  song awesome guys best love video hilarious lo...             1     1\n",
       "436                       many thumbs louis saving day             1     1\n",
       "437                                               nice             1     0\n",
       "\n",
       "[438 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reorganize columns\n",
    "columns=[\"CONTENT\", \"COMMENT_COUNT\",\"CLASS\"]\n",
    "df1=df1[columns]\n",
    "df2=df2[columns]\n",
    "df3=df3[columns]\n",
    "df4=df4[columns]\n",
    "df5=df5[columns]\n",
    "\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>COMMENT_COUNT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>huh anyway check tube channel kobyoshi</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hey guys check new channel first vid us monkey...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test say murdev com</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shaking sexy ass channel enjoy _</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watch v vtarggvgtwq check</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>billion views planet lol</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>watching</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>subscribe call duty vids give aways goal subs</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>hi guys please android photo editor download t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>first billion viewed thought really cool billi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1838 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               CONTENT COMMENT_COUNT CLASS\n",
       "0               huh anyway check tube channel kobyoshi             1     1\n",
       "1    hey guys check new channel first vid us monkey...             1     1\n",
       "2                                  test say murdev com             1     1\n",
       "3                     shaking sexy ass channel enjoy _             1     1\n",
       "4                            watch v vtarggvgtwq check             1     1\n",
       "..                                                 ...           ...   ...\n",
       "345                           billion views planet lol             1     0\n",
       "346                                           watching             1     0\n",
       "347      subscribe call duty vids give aways goal subs             1     1\n",
       "348  hi guys please android photo editor download t...             1     1\n",
       "349  first billion viewed thought really cool billi...             1     0\n",
       "\n",
       "[1838 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df1, df2, df3, df4, df5])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CONTENT          object\n",
       "COMMENT_COUNT    object\n",
       "CLASS            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CONTENT          object\n",
       "COMMENT_COUNT     int64\n",
       "CLASS             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"COMMENT_COUNT\",\"CLASS\"]]=df[[\"COMMENT_COUNT\",\"CLASS\"]].apply(pd.to_numeric)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>COMMENT_COUNT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>huh anyway check tube channel kobyoshi</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hey guys check new channel first vid us monkey...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test say murdev com</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shaking sexy ass channel enjoy _</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watch v vtarggvgtwq check</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>billion views planet lol</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>watching</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>subscribe call duty vids give aways goal subs</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>hi guys please android photo editor download t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>first billion viewed thought really cool billi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1838 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               CONTENT  COMMENT_COUNT  CLASS\n",
       "0               huh anyway check tube channel kobyoshi              1      1\n",
       "1    hey guys check new channel first vid us monkey...              1      1\n",
       "2                                  test say murdev com              1      1\n",
       "3                     shaking sexy ass channel enjoy _              1      1\n",
       "4                            watch v vtarggvgtwq check              1      1\n",
       "..                                                 ...            ...    ...\n",
       "345                           billion views planet lol              1      0\n",
       "346                                           watching              1      0\n",
       "347      subscribe call duty vids give aways goal subs              1      1\n",
       "348  hi guys please android photo editor download t...              1      1\n",
       "349  first billion viewed thought really cool billi...              1      0\n",
       "\n",
       "[1838 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"author_count_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEAN API DATASETS WITH COMMENT COUNT COLUMN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>thumbsup</th>\n",
       "      <th>text</th>\n",
       "      <th># of replies</th>\n",
       "      <th>replies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ugy4RpuyuHCiq6Lj_8B4AaABAg</td>\n",
       "      <td>CBS News</td>\n",
       "      <td>1</td>\n",
       "      <td>Click here for more world news: https://youtub...</td>\n",
       "      <td>1</td>\n",
       "      <td>['Thanks for Always Watching our Videos and co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ugz2nww5rp6bmA86Xt14AaABAg</td>\n",
       "      <td>Foo Cortez</td>\n",
       "      <td>0</td>\n",
       "      <td>what a great accomplishment, UK!  Surely elect...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UgwIJbvA_JidBhZxfXt4AaABAg</td>\n",
       "      <td>Roc</td>\n",
       "      <td>0</td>\n",
       "      <td>Another suit pretending to represent the people.</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ugxq4KYBZpROL_OqY-B4AaABAg</td>\n",
       "      <td>SHINE - on -TV</td>\n",
       "      <td>0</td>\n",
       "      <td>This is the man from the world economic forum ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UgwbF45YM0RCCSVK-UV4AaABAg</td>\n",
       "      <td>Bill Paul</td>\n",
       "      <td>0</td>\n",
       "      <td>Congratulations! Celebrate Dipavali at 10 Down...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Ugw6bnq374CXREmrK-R4AaABAg</td>\n",
       "      <td>i love President Trump</td>\n",
       "      <td>14</td>\n",
       "      <td>UK has gone woke and soft, final nail in the c...</td>\n",
       "      <td>6</td>\n",
       "      <td>[\"He's an extremely wealthy hardworking, busin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>UgwPSCYGXz-Yv3yxs5F4AaABAg</td>\n",
       "      <td>Sean Lann</td>\n",
       "      <td>12</td>\n",
       "      <td>PM richer than the king XD</td>\n",
       "      <td>6</td>\n",
       "      <td>[\"except the king didn't earn it\", \"Their fami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Ugzp4Pdf8HTrbx6Ojv94AaABAg</td>\n",
       "      <td>Tibore Goldberger</td>\n",
       "      <td>0</td>\n",
       "      <td>🤡🤡🤡🤡🤡🤡🤡🤡💩💩💩💩💩💩💩💩💩💩😱😵😵😵🥴🥴🥴🥴🥴🥴🥴🥴🤡🤡🤡🤡🤡🤡💩💩💩💩💩💩💩💩💩💩</td>\n",
       "      <td>2</td>\n",
       "      <td>['@+①③②①③⑧④⑧⑤⑧⑦ WhatsApp Nation of Islam ideol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Ugx16QtYBlI6-wue9Fl4AaABAg</td>\n",
       "      <td>Siyr Quintana</td>\n",
       "      <td>0</td>\n",
       "      <td>⚠ATTENTION⚠ Volodimir Zelensky wants commit te...</td>\n",
       "      <td>1</td>\n",
       "      <td>['Thanks for Always Watching our Videos and co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>UgzPgrPHNO4Kv3A9Gtd4AaABAg</td>\n",
       "      <td>sravan vlogs</td>\n",
       "      <td>47</td>\n",
       "      <td>Real Diwali has started today since the appoin...</td>\n",
       "      <td>5</td>\n",
       "      <td>['@Kartik S Kumar lavade pata nahi kya tuzhe 😂...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id                  author  thumbsup  \\\n",
       "0    Ugy4RpuyuHCiq6Lj_8B4AaABAg                CBS News         1   \n",
       "1    Ugz2nww5rp6bmA86Xt14AaABAg              Foo Cortez         0   \n",
       "2    UgwIJbvA_JidBhZxfXt4AaABAg                     Roc         0   \n",
       "3    Ugxq4KYBZpROL_OqY-B4AaABAg          SHINE - on -TV         0   \n",
       "4    UgwbF45YM0RCCSVK-UV4AaABAg               Bill Paul         0   \n",
       "..                          ...                     ...       ...   \n",
       "156  Ugw6bnq374CXREmrK-R4AaABAg  i love President Trump        14   \n",
       "157  UgwPSCYGXz-Yv3yxs5F4AaABAg               Sean Lann        12   \n",
       "158  Ugzp4Pdf8HTrbx6Ojv94AaABAg       Tibore Goldberger         0   \n",
       "159  Ugx16QtYBlI6-wue9Fl4AaABAg           Siyr Quintana         0   \n",
       "160  UgzPgrPHNO4Kv3A9Gtd4AaABAg            sravan vlogs        47   \n",
       "\n",
       "                                                  text  # of replies  \\\n",
       "0    Click here for more world news: https://youtub...             1   \n",
       "1    what a great accomplishment, UK!  Surely elect...             0   \n",
       "2     Another suit pretending to represent the people.             0   \n",
       "3    This is the man from the world economic forum ...             0   \n",
       "4    Congratulations! Celebrate Dipavali at 10 Down...             0   \n",
       "..                                                 ...           ...   \n",
       "156  UK has gone woke and soft, final nail in the c...             6   \n",
       "157                         PM richer than the king XD             6   \n",
       "158     🤡🤡🤡🤡🤡🤡🤡🤡💩💩💩💩💩💩💩💩💩💩😱😵😵😵🥴🥴🥴🥴🥴🥴🥴🥴🤡🤡🤡🤡🤡🤡💩💩💩💩💩💩💩💩💩💩             2   \n",
       "159  ⚠ATTENTION⚠ Volodimir Zelensky wants commit te...             1   \n",
       "160  Real Diwali has started today since the appoin...             5   \n",
       "\n",
       "                                               replies  \n",
       "0    ['Thanks for Always Watching our Videos and co...  \n",
       "1                                                   []  \n",
       "2                                                   []  \n",
       "3                                                   []  \n",
       "4                                                   []  \n",
       "..                                                 ...  \n",
       "156  [\"He's an extremely wealthy hardworking, busin...  \n",
       "157  [\"except the king didn't earn it\", \"Their fami...  \n",
       "158  ['@+①③②①③⑧④⑧⑤⑧⑦ WhatsApp Nation of Islam ideol...  \n",
       "159  ['Thanks for Always Watching our Videos and co...  \n",
       "160  ['@Kartik S Kumar lavade pata nahi kya tuzhe 😂...  \n",
       "\n",
       "[161 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import datasets from api find\n",
    "df1=pd.read_csv(\"https://raw.githubusercontent.com/SNEHALDD/Youtube_Comments_Bot_Analysis/main/Youtube_Analysis/csv/what%20happened.%20comments.csv\")\n",
    "df2=pd.read_csv(\"https://raw.githubusercontent.com/SNEHALDD/Youtube_Comments_Bot_Analysis/main/Youtube_Analysis/csv/Snarky%20Puppy%20-%20Trinity%20(Extended%20Version)%20(Empire%20Central)%20comments.csv\")\n",
    "df3=pd.read_csv(\"https://raw.githubusercontent.com/SNEHALDD/Youtube_Comments_Bot_Analysis/main/Youtube_Analysis/csv/Shooter%20in%20custody%20after%20allegedly%20killing%202%20at%20Methodist%20Dallas%20Medical%20Center%20comments.csv\")\n",
    "df4=pd.read_csv(\"https://raw.githubusercontent.com/SNEHALDD/Youtube_Comments_Bot_Analysis/main/Youtube_Analysis/csv/Rishi%20Sunak%20to%20make%20history%20as%20U.K.'s%20next%20prime%20minister%20comments.csv\")\n",
    "df5=pd.read_csv(\"https://raw.githubusercontent.com/SNEHALDD/Youtube_Comments_Bot_Analysis/main/Youtube_Analysis/csv/Justice%20Thomas%20Temporarily%20Blocks%20Graham%20Testimony%20In%20Georgia%20Election%20Interference%20Probe%20comments.csv\")\n",
    "\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>thumbsup</th>\n",
       "      <th>text</th>\n",
       "      <th># of replies</th>\n",
       "      <th>replies</th>\n",
       "      <th>COMMENT_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UgySxNLGBmkYrsDnapt4AaABAg</td>\n",
       "      <td>Ali</td>\n",
       "      <td>0</td>\n",
       "      <td>Elhamdülillah ya rabbi</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ugxn6a-JIJlcsZv7Zd94AaABAg</td>\n",
       "      <td>J NS</td>\n",
       "      <td>0</td>\n",
       "      <td>They can’t say nurses because the hospitals fe...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UgydfG-SlyXqgCGqFv94AaABAg</td>\n",
       "      <td>Terry</td>\n",
       "      <td>0</td>\n",
       "      <td>They're not going to give you a motive, here's...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UgytJ_XGegcbdGngPIF4AaABAg</td>\n",
       "      <td>smc130TX</td>\n",
       "      <td>0</td>\n",
       "      <td>Two registered nurses!!!</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UgwIPLV5wdJ4FKN3zrN4AaABAg</td>\n",
       "      <td>ASS KETCHUP</td>\n",
       "      <td>0</td>\n",
       "      <td>These comments crack me up. If you hate guns a...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>UgxD4ynHgQ3CICApPYl4AaABAg</td>\n",
       "      <td>Lezo Brandon</td>\n",
       "      <td>1</td>\n",
       "      <td>Welcome to Joe Biden's America really went dow...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>UgxJt-edztGwRAkqnId4AaABAg</td>\n",
       "      <td>oldestgamer</td>\n",
       "      <td>2</td>\n",
       "      <td>hmm, why didn't they treat the shooter at Meth...</td>\n",
       "      <td>2</td>\n",
       "      <td>['He was stabilized and transferred to another...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>UgwOfCN7LIoNUiZpnSN4AaABAg</td>\n",
       "      <td>Gus Garza</td>\n",
       "      <td>11</td>\n",
       "      <td>No place is safe anymore! This is sad what thi...</td>\n",
       "      <td>12</td>\n",
       "      <td>['@dingus Pick one', '@resident rump Which tri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>UgxZtX-Kwvc27Yr1kB54AaABAg</td>\n",
       "      <td>Cyan Kirkpatrick</td>\n",
       "      <td>0</td>\n",
       "      <td>😡😓💔❣️🙏🥺☦️🕊️</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>UgxShZRJtJX5dL1FHKR4AaABAg</td>\n",
       "      <td>Daniel Gontar</td>\n",
       "      <td>9</td>\n",
       "      <td>oxycodone addict</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"Id think more to it than that. I'm a chronic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id            author  thumbsup  \\\n",
       "0    UgySxNLGBmkYrsDnapt4AaABAg               Ali         0   \n",
       "1    Ugxn6a-JIJlcsZv7Zd94AaABAg              J NS         0   \n",
       "2    UgydfG-SlyXqgCGqFv94AaABAg             Terry         0   \n",
       "3    UgytJ_XGegcbdGngPIF4AaABAg          smc130TX         0   \n",
       "4    UgwIPLV5wdJ4FKN3zrN4AaABAg       ASS KETCHUP         0   \n",
       "..                          ...               ...       ...   \n",
       "121  UgxD4ynHgQ3CICApPYl4AaABAg      Lezo Brandon         1   \n",
       "122  UgxJt-edztGwRAkqnId4AaABAg       oldestgamer         2   \n",
       "123  UgwOfCN7LIoNUiZpnSN4AaABAg         Gus Garza        11   \n",
       "124  UgxZtX-Kwvc27Yr1kB54AaABAg  Cyan Kirkpatrick         0   \n",
       "125  UgxShZRJtJX5dL1FHKR4AaABAg     Daniel Gontar         9   \n",
       "\n",
       "                                                  text  # of replies  \\\n",
       "0                               Elhamdülillah ya rabbi             0   \n",
       "1    They can’t say nurses because the hospitals fe...             0   \n",
       "2    They're not going to give you a motive, here's...             0   \n",
       "3                             Two registered nurses!!!             0   \n",
       "4    These comments crack me up. If you hate guns a...             0   \n",
       "..                                                 ...           ...   \n",
       "121  Welcome to Joe Biden's America really went dow...             0   \n",
       "122  hmm, why didn't they treat the shooter at Meth...             2   \n",
       "123  No place is safe anymore! This is sad what thi...            12   \n",
       "124                                        😡😓💔❣️🙏🥺☦️🕊️             0   \n",
       "125                                   oxycodone addict             1   \n",
       "\n",
       "                                               replies  COMMENT_COUNT  \n",
       "0                                                   []              1  \n",
       "1                                                   []              2  \n",
       "2                                                   []              1  \n",
       "3                                                   []              1  \n",
       "4                                                   []              1  \n",
       "..                                                 ...            ...  \n",
       "121                                                 []              1  \n",
       "122  ['He was stabilized and transferred to another...              1  \n",
       "123  ['@dingus Pick one', '@resident rump Which tri...              1  \n",
       "124                                                 []              1  \n",
       "125  [\"Id think more to it than that. I'm a chronic...              1  \n",
       "\n",
       "[126 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add amount of times each user made a comment on the video column\n",
    "df1[\"COMMENT_COUNT\"]=df1.groupby(['author'])['text'].transform('count')\n",
    "df2[\"COMMENT_COUNT\"]=df2.groupby(['author'])['text'].transform('count')\n",
    "df3[\"COMMENT_COUNT\"]=df3.groupby(['author'])['text'].transform('count')\n",
    "df4[\"COMMENT_COUNT\"]=df4.groupby(['author'])['text'].transform('count')\n",
    "df5[\"COMMENT_COUNT\"]=df5.groupby(['author'])['text'].transform('count')\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zara/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "/Users/zara/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>COMMENT_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>done much worse things take interview dr fauci...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thought issue realized happened anniversary mo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wait cheated sounds like dude mass murderer pl...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>issue force another employee big deal</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oh gosh</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51287</th>\n",
       "      <td>first</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51288</th>\n",
       "      <td>way</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51289</th>\n",
       "      <td>good</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51290</th>\n",
       "      <td>im early early</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51291</th>\n",
       "      <td>wow</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51286 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text COMMENT_COUNT\n",
       "0      done much worse things take interview dr fauci...           1.0\n",
       "1      thought issue realized happened anniversary mo...           1.0\n",
       "2      wait cheated sounds like dude mass murderer pl...           1.0\n",
       "3                  issue force another employee big deal           1.0\n",
       "4                                                oh gosh           1.0\n",
       "...                                                  ...           ...\n",
       "51287                                              first           1.0\n",
       "51288                                                way           1.0\n",
       "51289                                               good           1.0\n",
       "51290                                     im early early           1.0\n",
       "51291                                                wow           2.0\n",
       "\n",
       "[51286 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean data- df1\n",
    "df1=df1.drop(columns=[\"id\", \"author\",\"thumbsup\",\"# of replies\",\"replies\"])\n",
    "df1=df1.dropna()\n",
    "#remove urls, special characters, and punctuations, trailing spaces, emojis\n",
    "df1=df1.astype(str).apply(lambda x: x.str.encode('ascii','ignore').str.decode('ascii'))\n",
    "df1['text']= df1['text'].str.replace('http[s]?://(?:[a-zA-Z]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',' ')\n",
    "df1['text']=df1['text'].str.replace('\\W',' ',regex=True)\n",
    "df1['text']=df1['text'].str.replace('\\d+',' ')\n",
    "#everything to lowercase\n",
    "df1['text']=df1['text'].str.lower()\n",
    "#remove stopwords\n",
    "stop_words=set(stopwords.words('english'))\n",
    "def remove_stop(x):\n",
    "    return (\" \").join([word for word in str(x).split() if word not in stop_words])\n",
    "\n",
    "df1[\"text\"]=df1[\"text\"].apply(lambda x: remove_stop(x))\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zara/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "/Users/zara/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#clean data- df1\n",
    "df2=df2.drop(columns=[\"id\", \"author\",\"thumbsup\",\"# of replies\",\"replies\"])\n",
    "df2=df2.dropna()\n",
    "#remove urls, special characters, and punctuations, trailing spaces, emojis\n",
    "df2=df2.astype(str).apply(lambda x: x.str.encode('ascii','ignore').str.decode('ascii'))\n",
    "df2['text']= df2['text'].str.replace('http[s]?://(?:[a-zA-Z]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',' ')\n",
    "df2['text']=df2['text'].str.replace('\\W',' ',regex=True)\n",
    "df2['text']=df2['text'].str.replace('\\d+',' ')\n",
    "#everything to lowercase\n",
    "df1['text']=df2['text'].str.lower()\n",
    "#remove stopwords\n",
    "stop_words=set(stopwords.words('english'))\n",
    "def remove_stop(x):\n",
    "    return (\" \").join([word for word in str(x).split() if word not in stop_words])\n",
    "\n",
    "df2[\"text\"]=df2[\"text\"].apply(lambda x: remove_stop(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zara/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "/Users/zara/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>COMMENT_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elhamdlillah ya rabbi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cant say nurses hospitals fear losing grip pow...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>going give motive hipaa laws actually apply si...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>two registered nurses</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comments crack hate guns want guns banned move...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>welcome joe biden america really went hill fast</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>hmm treat shooter methodist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>place safe anymore sad country going thru n th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>oxycodone addict</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text COMMENT_COUNT\n",
       "0                                elhamdlillah ya rabbi             1\n",
       "1    cant say nurses hospitals fear losing grip pow...             2\n",
       "2    going give motive hipaa laws actually apply si...             1\n",
       "3                                two registered nurses             1\n",
       "4    comments crack hate guns want guns banned move...             1\n",
       "..                                                 ...           ...\n",
       "121    welcome joe biden america really went hill fast             1\n",
       "122                        hmm treat shooter methodist             1\n",
       "123  place safe anymore sad country going thru n th...             1\n",
       "124                                                                1\n",
       "125                                   oxycodone addict             1\n",
       "\n",
       "[126 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean data- df1\n",
    "df3=df3.drop(columns=[\"id\", \"author\",\"thumbsup\",\"# of replies\",\"replies\"])\n",
    "df3=df3.dropna()\n",
    "#remove urls, special characters, and punctuations, trailing spaces, emojis\n",
    "df3=df3.astype(str).apply(lambda x: x.str.encode('ascii','ignore').str.decode('ascii'))\n",
    "df3['text']= df3['text'].str.replace('http[s]?://(?:[a-zA-Z]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',' ')\n",
    "df3['text']=df3['text'].str.replace('\\W',' ',regex=True)\n",
    "df3['text']=df3['text'].str.replace('\\d+',' ')\n",
    "#everything to lowercase\n",
    "df3['text']=df3['text'].str.lower()\n",
    "#remove stopwords\n",
    "stop_words=set(stopwords.words('english'))\n",
    "def remove_stop(x):\n",
    "    return (\" \").join([word for word in str(x).split() if word not in stop_words])\n",
    "\n",
    "df3[\"text\"]=df3[\"text\"].apply(lambda x: remove_stop(x))\n",
    "\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zara/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "/Users/zara/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#clean data- df1\n",
    "df4=df4.drop(columns=[\"id\", \"author\",\"thumbsup\",\"# of replies\",\"replies\"])\n",
    "df4=df4.dropna()\n",
    "#remove urls, special characters, and punctuations, trailing spaces, emojis\n",
    "df4=df4.astype(str).apply(lambda x: x.str.encode('ascii','ignore').str.decode('ascii'))\n",
    "df4['text']= df4['text'].str.replace('http[s]?://(?:[a-zA-Z]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',' ')\n",
    "df4['text']=df4['text'].str.replace('\\W',' ',regex=True)\n",
    "df4['text']=df4['text'].str.replace('\\d+',' ')\n",
    "#everything to lowercase\n",
    "df4['text']=df4['text'].str.lower()\n",
    "#remove stopwords\n",
    "stop_words=set(stopwords.words('english'))\n",
    "def remove_stop(x):\n",
    "    return (\" \").join([word for word in str(x).split() if word not in stop_words])\n",
    "\n",
    "df4[\"text\"]=df4[\"text\"].apply(lambda x: remove_stop(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zara/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "/Users/zara/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>COMMENT_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>america done cant even continue insane mess</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fighting supreme court frustrating</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>justice house ninja</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uncle thomas justice</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clarence thomas corrupt traitor removed suprem...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>corrupt see look yo word</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>call preferential treatment big time</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>revolution</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>rats stick together</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>absolute travesty justice impeach remove recus...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>921 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text COMMENT_COUNT\n",
       "0          america done cant even continue insane mess             1\n",
       "1                   fighting supreme court frustrating             1\n",
       "2                                  justice house ninja             1\n",
       "3                                 uncle thomas justice             1\n",
       "4    clarence thomas corrupt traitor removed suprem...             2\n",
       "..                                                 ...           ...\n",
       "916                           corrupt see look yo word             1\n",
       "917               call preferential treatment big time             1\n",
       "918                                         revolution             1\n",
       "919                                rats stick together             1\n",
       "920  absolute travesty justice impeach remove recus...             3\n",
       "\n",
       "[921 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean data- df1\n",
    "df5=df5.drop(columns=[\"id\", \"author\",\"thumbsup\",\"# of replies\",\"replies\"])\n",
    "df5=df5.dropna()\n",
    "#remove urls, special characters, and punctuations, trailing spaces, emojis\n",
    "df5=df5.astype(str).apply(lambda x: x.str.encode('ascii','ignore').str.decode('ascii'))\n",
    "df5['text']= df5['text'].str.replace('http[s]?://(?:[a-zA-Z]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',' ')\n",
    "df5['text']=df5['text'].str.replace('\\W',' ',regex=True)\n",
    "df5['text']=df5['text'].str.replace('\\d+',' ')\n",
    "#everything to lowercase\n",
    "df5['text']=df5['text'].str.lower()\n",
    "#remove stopwords\n",
    "stop_words=set(stopwords.words('english'))\n",
    "def remove_stop(x):\n",
    "    return (\" \").join([word for word in str(x).split() if word not in stop_words])\n",
    "\n",
    "df5[\"text\"]=df5[\"text\"].apply(lambda x: remove_stop(x))\n",
    "\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the df\n",
    "df1.to_csv(\"author_count_what_happened.csv\")\n",
    "df2.to_csv(\"author_count_snarky_puppy.csv\")\n",
    "df3.to_csv(\"author_count_methodist_shooter.csv\")\n",
    "df4.to_csv(\"author_count_prime_minister.csv\")\n",
    "df5.to_csv(\"author_count_justice_thomas.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MACHINE LEARNING ATTEMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ml dependecies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df=df[[\"CONTENT\",\"COMMENT_COUNT\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2, 1470]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ks/pgs7v2gn6pq2dd8mz9mtsrpw0000gn/T/ipykernel_5704/88563343.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfeatures_test\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             )\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/mlenv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    332\u001b[0m         raise ValueError(\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2, 1470]"
     ]
    }
   ],
   "source": [
    "#train the data\n",
    "z = feature_df\n",
    "y = df[\"CLASS\"]\n",
    "z_train, z_test,y_train, y_test = train_test_split(z,y,test_size = 0.2)\n",
    "\n",
    "cv = CountVectorizer()\n",
    "features = cv.fit_transform(z_train)\n",
    "\n",
    "model = svm.SVC()\n",
    "model.fit(features,y_train)\n",
    "\n",
    "features_test= cv.transform(z_test)\n",
    "print(model.score(features_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4f1b2b26d282679a37c22ffd0d805ae9e6e49f4c74aa42e69980383f9b2a98b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
